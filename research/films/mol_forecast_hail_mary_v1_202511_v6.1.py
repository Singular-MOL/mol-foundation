#!/usr/bin/env python3
"""
MOL-–ê–ù–ê–õ–ò–ó 6.1 ‚Äî –ü–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è Termux / –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
–†–µ–∞–ª–∏–∑—É–µ—Ç:
 - mol_score –∏ —è–≤–Ω—ã–π O(E)
 - —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é (PFE) –ø—Ä–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–µ
 - Œ¶-–æ–ø–µ—Ä–∞—Ç–æ—Ä —á–µ—Ä–µ–∑ —Ç—Ä–µ–π–ª–µ—Ä (apply_trailer_phi) —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
 - —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –±–µ–∑ sklearn
 - —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç—ã, –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –≤–∫–ª–∞–¥–æ–≤
 - —ç–∫—Å–ø–æ—Ä—Ç JSON-–æ—Ç—á—ë—Ç–∞ —Å phi_sources
–ê–≤—Ç–æ—Ä: –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
–î–∞—Ç–∞: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
"""
import json
import math
import random
from datetime import datetime

class FullMOLAnalyzer:
    def __init__(self):
        self.analysis_date = datetime.now().strftime("%Y-%m-%d")
        self.historical_films = self.load_extended_historical_data()
        self.calibrated_weights = self.simple_calibration()
        self.validate_calibration()
        # last_phi_sources –±—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω –ø—Ä–∏ apply_trailer_phi
        self.last_phi_sources = {}

    # === –î–ê–ù–ù–´–ï ===
    def load_extended_historical_data(self):
        """–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (N=10 –ø–æ –≤–µ—Ä—Å–∏–∏ 5.0)"""
        return [
            {'title':'–ú–∞—Ä—Å–∏–∞–Ω–∏–Ω','budget':108_000_000,'box_office':630_200_000,'imdb_score':8.0,'success':1.0,
             'principles':{'PIVC':0.85,'PLOA':0.80,'PAA':0.75,'PDC':0.70}},
            {'title':'–ò–Ω—Ç–µ—Ä—Å—Ç–µ–ª–ª–∞—Ä','budget':165_000_000,'box_office':677_500_000,'imdb_score':8.6,'success':1.0,
             'principles':{'PIVC':0.90,'PLOA':0.85,'PAA':0.80,'PDC':0.75}},
            {'title':'–ì—Ä–∞–≤–∏—Ç–∞—Ü–∏—è','budget':100_000_000,'box_office':723_200_000,'imdb_score':7.7,'success':1.0,
             'principles':{'PIVC':0.88,'PLOA':0.82,'PAA':0.78,'PDC':0.72}},
            {'title':'–ü—Ä–∏–±—ã—Ç–∏–µ','budget':47_000_000,'box_office':203_400_000,'imdb_score':7.9,'success':0.8,
             'principles':{'PIVC':0.82,'PLOA':0.75,'PAA':0.85,'PDC':0.68}},
            {'title':'–ò–∑–≥–æ–π-–æ–¥–∏–Ω','budget':200_000_000,'box_office':1_056_100_000,'imdb_score':7.8,'success':1.0,
             'principles':{'PIVC':0.78,'PLOA':0.72,'PAA':0.70,'PDC':0.82}},
            {'title':'–ü–µ—Ä–≤—ã–π —á–µ–ª–æ–≤–µ–∫','budget':70_000_000,'box_office':105_800_000,'imdb_score':7.3,'success':0.4,
             'principles':{'PIVC':0.75,'PLOA':0.70,'PAA':0.65,'PDC':0.60}},
            {'title':'–ê—Ä—Ç–µ–º–∏—Å –§–∞—É–ª','budget':125_000_000,'box_office':167_800_000,'imdb_score':6.2,'success':0.3,
             'principles':{'PIVC':0.60,'PLOA':0.55,'PAA':0.58,'PDC':0.52}},
            {'title':'–°—Ñ–µ—Ä–∞','budget':80_000_000,'box_office':37_300_000,'imdb_score':6.6,'success':0.1,
             'principles':{'PIVC':0.45,'PLOA':0.50,'PAA':0.40,'PDC':0.35}},
            {'title':'–í—Ä–µ–º—è','budget':40_000_000,'box_office':18_000_000,'imdb_score':5.7,'success':0.1,
             'principles':{'PIVC':0.38,'PLOA':0.42,'PAA':0.35,'PDC':0.30}},
            {'title':'–î–∂–æ–Ω–Ω–∏-–º–Ω–µ–º–æ–Ω–∏–∫','budget':28_000_000,'box_office':52_400_000,'imdb_score':5.6,'success':0.2,
             'principles':{'PIVC':0.42,'PLOA':0.38,'PAA':0.45,'PDC':0.40}}
        ]

    # === –ö–ê–õ–ò–ë–†–û–í–ö–ê ===
    def simple_calibration(self):
        """
        –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º —Å success (–∞–±—Å–æ–ª—é—Ç–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è),
        —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º PFE-—Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (—Å–º. white paper).
        """
        principles = ['PIVC','PLOA','PAA','PDC']
        correlations = {}
        for p in principles:
            corr = self.calculate_correlation(
                [f['principles'][p] for f in self.historical_films],
                [f['success'] for f in self.historical_films]
            )
            # PFE ‚Äî —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏—è: —É—Ä–æ–≤–Ω–∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ (–ø—Ä–∏–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
            level = {'PIVC':1,'PLOA':2,'PAA':2,'PDC':1}[p]
            correlations[p] = abs(corr) / (level if level > 0 else 1)

        total = sum(correlations.values()) or 1.0
        weights = {p: correlations[p]/total for p in correlations}
        print("üîß –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ (PFE-normalized):")
        for p,w in weights.items():
            print(f"   {p}: {w:.3f}")
        return weights

    def calculate_correlation(self,x,y):
        """–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞ (–±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫)"""
        n=len(x)
        if n<2:
            return 0.0
        sx,sumx2,sy,sumy2,sumxy = 0,0,0,0,0
        for i in range(n):
            sx += x[i]; sy += y[i]
            sumx2 += x[i]*x[i]; sumy2 += y[i]*y[i]
            sumxy += x[i]*y[i]
        num = n*sumxy - sx*sy
        den_sq = (n*sumx2 - sx*sx) * (n*sumy2 - sy*sy)
        if den_sq <= 0:
            return 0.0
        return num / math.sqrt(den_sq)

    def validate_calibration(self):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Å–æ–≤"""
        total = sum(self.calibrated_weights.values())
        if not math.isclose(total, 1.0, rel_tol=1e-6):
            for p in list(self.calibrated_weights.keys()):
                self.calibrated_weights[p] /= total
        print("‚úÖ –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞")

    # === –ê–ù–ê–õ–ò–ó ===
    def analyze_hail_mary(self):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑: —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç mol_score, ontological load, –∏–Ω–¥–µ–∫—Å –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏,
        –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Ä–æ–≥ –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤—ã–∑—ã–≤–∞–µ—Ç Œ¶-–ø–µ—Ä–µ–∫–∞–ª–∏–±—Ä–æ–≤–∫—É.
        """
        hail_mary = {'PIVC':0.85,'PLOA':0.78,'PAA':0.80,'PDC':0.76}
        mol_score = sum(hail_mary[p] * self.calibrated_weights[p] for p in self.calibrated_weights)
        ontological_load = 1.0 - mol_score
        asymmetry_index = 1.0 - (min(hail_mary.values()) / max(hail_mary.values()))

        print(f"\nüìä MOL-–ø–æ–∫–∞–∑–∞—Ç–µ–ª—å: {mol_score:.3f}")
        print(f"üß† O(E) = {ontological_load:.3f} | –ò–Ω–¥–µ–∫—Å –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏ = {asymmetry_index:.3f}")

        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ œÑ (–ø–æ white paper –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å)
        CRITICAL_LOAD = 0.7
        phi_activated = False
        if ontological_load > CRITICAL_LOAD:
            print(f"‚ö†Ô∏è O(E) > {CRITICAL_LOAD} ‚Üí –∞–∫—Ç–∏–≤–∞—Ü–∏—è Œ¶-–æ–ø–µ—Ä–∞—Ç–æ—Ä–∞")
            self.recalibrate_phi()
            phi_activated = True

        box_pred = self.simple_box_office_prediction(mol_score)
        val = self.custom_cross_validation()

        return {
            'date': self.analysis_date,
            'film': 'Project Hail Mary (–ü—Ä–æ–µ–∫—Ç "–ö–æ–Ω–µ—Ü —Å–≤–µ—Ç–∞")',
            'mol_score': mol_score,
            'ontological_load': ontological_load,
            'asymmetry_index': asymmetry_index,
            'phi_activated': phi_activated,
            'box_office_prediction': box_pred,
            'validation': val,
            'weights': self.calibrated_weights,
            'principles_breakdown': hail_mary,
            'phi_sources': self.last_phi_sources  # –±—É–¥–µ—Ç –ø—É—Å—Ç—ã–º, –µ—Å–ª–∏ apply_trailer_phi –Ω–µ –≤—ã–∑—ã–≤–∞–ª—Å—è
        }

    # === Œ¶-–û–ü–ï–†–ê–¢–û–† (–ø–µ—Ä–µ–∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ O(E)) ===
    def recalibrate_phi(self):
        """–ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–∫—Ü–∏–æ–Ω–Ω–∞—è –ø–µ—Ä–µ–∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ (–∏–º–∏—Ç–∞—Ü–∏—è Œ¶-—Å–∫–∞—á–∫–∞)"""
        print("üîÑ –ü–µ—Ä–µ–∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (Œ¶-–æ–ø–µ—Ä–∞—Ç–æ—Ä –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω)...")
        # –í —Ä–µ–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—ã–µ —Ñ–∏–ª—å–º—ã –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ; –∑–¥–µ—Å—å ‚Äî –ø–µ—Ä–µ—Å—á—ë—Ç –≤–µ—Å–æ–≤
        self.calibrated_weights = self.simple_calibration()
        self.validate_calibration()
        print("‚úÖ Œ¶-—Å–¥–≤–∏–≥ –∑–∞–≤–µ—Ä—à–µ–Ω")

    # === –†–ï–ê–õ–¨–ù–´–ô Œ¶-–û–ü–ï–†–ê–¢–û–† –ß–ï–†–ï–ó –¢–†–ï–ô–õ–ï–† ===
    def apply_trailer_phi(self, trailer_metrics, sources=None):
        """
        –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Œ¶(E, Œ¥) —á–µ—Ä–µ–∑ —Ä–µ–∞–∫—Ü–∏—é –Ω–∞ —Ç—Ä–µ–π–ª–µ—Ä.
        trailer_metrics: dict, –Ω–∞–ø—Ä–∏–º–µ—Ä {'views': 400_000_000, 'like_ratio': 0.96, 'sentiment': 0.88}
        sources: dict/list —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (YouTube, ScreenRant, Wikipedia...)
        –ò–∑–º–µ–Ω—è–µ—Ç self.calibrated_weights –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç self.last_phi_sources.
        """
        print("\nüéûÔ∏è –ê–∫—Ç–∏–≤–∞—Ü–∏—è Œ¶ —á–µ—Ä–µ–∑ —Ç—Ä–µ–π–ª–µ—Ä–Ω–æ–µ –≤–æ–∑–º—É—â–µ–Ω–∏–µ Œ¥...")

        # --- 1. –í—ã—á–∏—Å–ª—è–µ–º —ç–Ω–µ—Ä–≥–∏—é Œ¥ ---
        views = float(trailer_metrics.get('views', 0))
        like_ratio = float(trailer_metrics.get('like_ratio', 0.8))
        sentiment = float(trailer_metrics.get('sentiment', 0.8))

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –∫ 100M (–ø—Ä–∏–±–ª. –¥–∏–∞–ø–∞–∑–æ–Ω 0..5)
        delta_energy = (views / 100_000_000.0) * sentiment * max(0.5, like_ratio)
        # –ì—Ä–∞–Ω–∏—Ü—ã sensible
        delta_energy = max(0.0, min(delta_energy, 5.0))
        print(f"   ‚öôÔ∏è –≠–Ω–µ—Ä–≥–∏—è –≤–æ–∑–º—É—â–µ–Ω–∏—è Œ¥ = {delta_energy:.3f} (views={int(views)}, like_ratio={like_ratio:.2f}, sentiment={sentiment:.2f})")

        # --- 2. –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –≤–µ—Å–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —ç–Ω–µ—Ä–≥–∏–∏ ---
        # –ß–µ–º –±–æ–ª—å—à–µ Œ¥ ‚Äî —Ç–µ–º —Å–∏–ª—å–Ω–µ–µ —É—Å–∏–ª–∏–≤–∞–µ–º PIVC/PDC (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ-–≤–∏–∑—É–∞–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã)
        # –∏ –º—è–≥–∫–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
        adjustment = min(0.20, 0.04 * delta_energy)  # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ +20%
        print(f"   üîß –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –≤–µ—Å–æ–≤: –±–∞–∑–æ–≤—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç = {adjustment:.4f}")

        new_weights = {}
        for p, w in self.calibrated_weights.items():
            if p in ['PIVC', 'PDC']:
                # —É—Å–∏–ª–µ–Ω–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ–º/–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                new_w = w * (1.0 + adjustment)
            else:
                # –Ω–µ–±–æ–ª—å—à–æ–µ –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è PLOA/PAA
                new_w = w * (1.0 - adjustment * 0.5)
            new_weights[p] = new_w

        # --- 3. –ü–µ—Ä–µ–Ω–æ—Ä–º–∏—Ä—É–µ–º (PFE) ---
        total = sum(new_weights.values()) or 1.0
        for p in new_weights:
            new_weights[p] /= total
        self.calibrated_weights = new_weights
        print(f"   ‚úÖ –í–µ—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω—ã: { {p:round(w,3) for p,w in self.calibrated_weights.items()} }")

        # --- 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –æ—Ç—á—ë—Ç–∞ ---
        self.last_phi_sources = sources or {"unknown": "no sources provided"}
        print(f"   üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {list(self.last_phi_sources.keys()) if isinstance(self.last_phi_sources, dict) else self.last_phi_sources}")

        print("‚úÖ Œ¶-—Å–¥–≤–∏–≥ –ø–æ —Ç—Ä–µ–π–ª–µ—Ä—É –∑–∞–≤–µ—Ä—à–µ–Ω ‚Äî –º–æ–¥–µ–ª—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–∫—Ü–∏–∏ –∞—É–¥–∏—Ç–æ—Ä–∏–∏.")

    # === –ü–†–û–ì–ù–û–û–ó ===
    def simple_box_office_prediction(self, mol_score):
        """–ü—Ä–æ—Å—Ç–∞—è –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑ sklearn)"""
        x=[]; y=[]
        for f in self.historical_films:
            s = sum(f['principles'][p] * self.calibrated_weights[p] for p in self.calibrated_weights)
            x.append(s); y.append(f['box_office'])
        n = len(x)
        if n < 3:
            avg = sum(y) / n if n>0 else 0
            return {'point_estimate': avg, 'millions': avg/1e6}
        sx = sum(x); sy = sum(y)
        sumx2 = sum(xi*xi for xi in x)
        sumxy = sum(x[i]*y[i] for i in range(n))
        den = n * sumx2 - sx * sx
        if abs(den) < 1e-12:
            avg = sy / n
            return {'point_estimate': avg, 'millions': avg/1e6}
        b = (n*sumxy - sx*sy) / den
        a = (sy - b * sx) / n
        pred = a + b * mol_score

        # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ —á–µ—Ä–µ–∑ std_error
        predictions = [a + b*xi for xi in x]
        errors = [y[i] - predictions[i] for i in range(n)]
        std_error = math.sqrt(sum(e*e for e in errors) / (n-2)) if n>2 else 0.0
        conf_lower = max(0.0, pred - 1.96*std_error)
        conf_upper = pred + 1.96*std_error

        return {
            'point_estimate': pred,
            'millions': pred / 1e6,
            'confidence_range_millions': [conf_lower/1e6, conf_upper/1e6]
        }

    # === –í–ê–õ–ò–î–ê–¶–ò–Ø (—Å–≤–æ—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è) ===
    def custom_cross_validation(self):
        """–ü—Ä–æ—Å—Ç–∞—è k-fold –±–µ–∑ sklearn: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç mean MAE"""
        data = self.historical_films.copy()
        random.seed(42)
        random.shuffle(data)
        n_folds = 5
        fold_size = max(1, len(data) // n_folds)
        mae_list = []
        for fold in range(n_folds):
            test_start = fold * fold_size
            test_end = test_start + fold_size if fold < n_folds - 1 else len(data)
            test_set = data[test_start:test_end]
            train_set = data[:test_start] + data[test_end:]
            if len(train_set) < 2:
                continue
            train_weights = self.calibrate_on_subset(train_set)
            preds = []
            acts = []
            for film in test_set:
                score = sum(film['principles'][p] * train_weights[p] for p in train_weights)
                preds.append(score)
                acts.append(film['success'])
            if not preds:
                continue
            mae = sum(abs(preds[i] - acts[i]) for i in range(len(preds))) / len(preds)
            mae_list.append(mae)
        mean_mae = sum(mae_list) / len(mae_list) if mae_list else 0.0
        stability = '–í—ã—Å–æ–∫–∞—è' if mean_mae < 0.2 else '–£–º–µ—Ä–µ–Ω–Ω–∞—è'
        return {'mean_MAE': mean_mae, 'folds': len(mae_list), 'stability': stability}

    def calibrate_on_subset(self, films_subset):
        """–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤ –Ω–∞ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ (–∞–Ω–∞–ª–æ–≥ simple_calibration)"""
        principles = ['PIVC','PLOA','PAA','PDC']
        correlations = {}
        for p in principles:
            corr = self.calculate_correlation(
                [f['principles'][p] for f in films_subset],
                [f['success'] for f in films_subset]
            )
            level = {'PIVC':1,'PLOA':2,'PAA':2,'PDC':1}[p]
            correlations[p] = abs(corr) / (level if level>0 else 1)
        total = sum(correlations.values()) or 1.0
        return {p: correlations[p]/total for p in correlations}

    # === –°–¢–†–ï–°–°-–¢–ï–°–¢–´ ===
    def stress_tests(self):
        cases = [
            {'name': '–ò–¥–µ–∞–ª—å–Ω—ã–π —Ñ–∏–ª—å–º', 'principles': {'PIVC':1.0, 'PLOA':1.0, 'PAA':1.0, 'PDC':1.0}},
            {'name': '–ê–Ω—Ç–∏—Ñ–∏–ª—å–º', 'principles': {'PIVC':0.0, 'PLOA':0.0, 'PAA':0.0, 'PDC':0.0}},
            {'name': '–ê—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π', 'principles': {'PIVC':0.9, 'PLOA':0.2, 'PAA':0.2, 'PDC':0.9}},
            {'name': '–¢–æ–ª—å–∫–æ PIVC', 'principles': {'PIVC':0.9, 'PLOA':0.1, 'PAA':0.1, 'PDC':0.1}}
        ]
        results = []
        for c in cases:
            principles = c['principles']
            score = sum(principles[p] * self.calibrated_weights[p] for p in self.calibrated_weights)
            Oe = 1.0 - score
            values = list(principles.values())
            asymmetry = 1.0 - (min(values) / max(values)) if max(values) > 0 else 1.0
            results.append({
                'case': c['name'],
                'mol_score': score,
                'O(E)': Oe,
                'asymmetry': asymmetry
            })
        return results

    # === –î–ï–¢–ê–õ–¨–ù–´–ô –†–ê–ó–ë–û–† ===
    def get_detailed_breakdown(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∫–ª–∞–¥ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–Ω—Ü–∏–ø–∞ –≤ mol_score"""
        hail_mary = {'PIVC':0.85,'PLOA':0.78,'PAA':0.80,'PDC':0.76}
        breakdown = {}
        total_score = sum(hail_mary[p] * self.calibrated_weights[p] for p in hail_mary)
        for p, score in hail_mary.items():
            weight = self.calibrated_weights[p]
            contribution = score * weight
            percentage = (contribution / total_score * 100) if total_score>0 else 0.0
            breakdown[p] = {'score': score, 'weight': weight, 'contribution': contribution, 'percentage': percentage}
        return breakdown

# === MAIN (–∑–∞–ø—É—Å–∫) ===
def main():
    print("üß¨ MOL-–ê–ù–ê–õ–ò–ó 6.1 ‚Äî —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–∫–æ–Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏ (Termux-ready)")
    print("="*72)
    analyzer = FullMOLAnalyzer()

    # --- –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–µ–π–ª–µ—Ä–Ω—ã–π Œ¶-–æ–ø–µ—Ä–∞—Ç–æ—Ä (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ) ---
    # –ï—Å–ª–∏ —Ç—ã —Ö–æ—á–µ—à—å –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å ‚Äî –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –±–ª–æ–∫ –Ω–∏–∂–µ.
    trailer_data = {
        'views': 400_000_000,      # –ø—Ä–∏–º–µ—Ä: 400M –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ (—Ç—Ä–µ–π–ª–µ—Ä record)
        'like_ratio': 0.96,        # –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ª–∞–π–∫–æ–≤/–¥–∏–∑–ª–∞–π–∫–æ–≤ (–ø—Ä–∏–º–µ—Ä)
        'sentiment': 0.87          # –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π sentiment (0..1), –º–æ–∂–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å —á–µ—Ä–µ–∑ social APIs
    }
    trailer_sources = {
        'ScreenRant': 'https://screenrant.com/project-hail-mary-ryan-gosling-box-office-fall-guy-redemption/',
        'YouTube (official trailer)': 'https://www.youtube.com/watch?v=--- (official trailer)',
        'Wikipedia': 'https://en.wikipedia.org/wiki/Project_Hail_Mary_(film)'
    }

    # –ü—Ä–∏–º–µ–Ω—è–µ–º Œ¶ —á–µ—Ä–µ–∑ —Ç—Ä–µ–π–ª–µ—Ä (–≤–ª–∏—è–µ—Ç –Ω–∞ calibrated_weights –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç sources)
    analyzer.apply_trailer_phi(trailer_data, trailer_sources)

    # --- –ê–Ω–∞–ª–∏–∑ (–¥–æ/–ø–æ—Å–ª–µ Œ¶ —Ç–µ–ø–µ—Ä—å –æ—Ç—Ä–∞–∂—ë–Ω –≤ –≤–µ—Å–∞—Ö) ---
    res = analyzer.analyze_hail_mary()

    # --- –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    bo = res['box_office_prediction']
    print(f"\nüí∞ –ü–†–û–ì–ù–û–ó –°–ë–û–†–û–í (—Ç–æ—á–µ—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞): ${bo['millions']:.1f}M")
    if 'confidence_range_millions' in bo:
        low, high = bo['confidence_range_millions']
        print(f"   –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: ${low:.1f}M - ${high:.1f}M")

    val = res['validation']
    print(f"\nüìà –í–ê–õ–ò–î–ê–¶–ò–Ø: mean_MAE = {val['mean_MAE']:.3f} (folds={val['folds']})")
    print(f"   –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {val['stability']}")

    # –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –≤–∫–ª–∞–¥–æ–≤
    print("\nüîç –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ –∏ –≤–∫–ª–∞–¥–æ–≤:")
    breakdown = analyzer.get_detailed_breakdown()
    for p, d in breakdown.items():
        print(f"   {p}: score={d['score']:.2f} √ó weight={d['weight']:.3f} => contribution={d['contribution']:.3f} ({d['percentage']:.1f}%)")

    # –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç—ã
    print("\nüß© –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç—ã:")
    stress = analyzer.stress_tests()
    for s in stress:
        print(f"   {s['case']}: MOL={s['mol_score']:.3f}, O(E)={s['O(E)']:.3f}, Asymmetry={s['asymmetry']:.3f}")

    # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è (–∫–æ—Ä–æ—Ç–∫–∞—è)
    mol_score = res['mol_score']
    print("\nüéØ –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø:")
    if mol_score > 0.7:
        print("   ‚úÖ –í–´–°–û–ö–ò–ô –ü–û–¢–ï–ù–¶–ò–ê–õ –£–°–ü–ï–•–ê ‚Äî —Ñ–∏–ª—å–º —Ö–æ—Ä–æ—à–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω –ø–æ MOL-–ø—Ä–∏–Ω—Ü–∏–ø–∞–º.")
    elif mol_score > 0.5:
        print("   ‚ö†Ô∏è –£–ú–ï–†–ï–ù–ù–´–ô –ü–û–¢–ï–ù–¶–ò–ê–õ ‚Äî –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–º–∞—Ä–∫–µ—Ç–∏–Ω–≥/–ø—Ä–∞–π—Å–∏–Ω–≥/—Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ).")
    else:
        print("   ‚ùå –ù–ò–ó–ö–ò–ô –ü–û–¢–ï–ù–¶–ò–ê–õ ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –∏–ª–∏ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥.")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç, –≤–∫–ª—é—á–∞—è –∏—Å—Ç–æ—á–Ω–∏–∫–∏ Œ¶
    out_filename = f"mol_analysis6_1_{res['date']}.json"
    # –î–æ–±–∞–≤–∏–º last_phi_sources –≤ –∑–∞–ø–∏—Å—å –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
    res['phi_sources'] = analyzer.last_phi_sources
    with open(out_filename, 'w', encoding='utf-8') as f:
        json.dump(res, f, ensure_ascii=False, indent=2)
    print(f"\nüíæ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_filename}")

if __name__ == "__main__":
    main()
